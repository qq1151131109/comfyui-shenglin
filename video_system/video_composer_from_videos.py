"""
AIè§†é¢‘åˆ¶ä½œå™¨ï¼ˆåŸè§†é¢‘åˆæˆå™¨-åŸºäºè§†é¢‘å‡çº§ç‰ˆï¼‰
æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
1. ä¼ ç»Ÿæ¨¡å¼ï¼šæ‹¼æ¥ç°æœ‰è§†é¢‘ç‰‡æ®µ
2. AIæ¨¡å¼ï¼šå›¾ç‰‡é€šè¿‡RunningHub Wan2.2ç”Ÿæˆè§†é¢‘åæ‹¼æ¥
åŒ…å«å®Œæ•´çš„éŸ³é¢‘åˆæˆã€å­—ä½“æ ‡é¢˜ã€éŸ³æ•ˆåº“åŠŸèƒ½
"""

import os
import sys
import tempfile
import subprocess
import shutil
import torch
import torchaudio
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import folder_paths
from typing import List, Dict, Any, Tuple, Generator, Optional
import json
import math
import asyncio
import aiohttp
import ssl
import io
import base64
import time

# å¯¼å…¥éŸ³æ•ˆç®¡ç†å™¨
try:
    current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, current_dir)
    from audio_effects_manager import AudioEffectsManager
    AUDIO_EFFECTS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ éŸ³æ•ˆåº“ä¸å¯ç”¨: {e}")
    AUDIO_EFFECTS_AVAILABLE = False

class AIVideoComposer:
    """
    AIè§†é¢‘åˆ¶ä½œå™¨
    - æ”¯æŒå›¾ç‰‡é€šè¿‡RunningHub Wan2.2 APIç”Ÿæˆè§†é¢‘
    - æ”¯æŒä¼ ç»Ÿè§†é¢‘ç‰‡æ®µæ‹¼æ¥
    - éŸ³æ•ˆåº“é›†æˆ
    - å­—ä½“æ ‡é¢˜å åŠ 
    - éŸ³é¢‘æ··åˆå’ŒåŒæ­¥
    """

    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        self.temp_dir = tempfile.gettempdir()

        # åˆå§‹åŒ–éŸ³æ•ˆç®¡ç†å™¨
        if AUDIO_EFFECTS_AVAILABLE:
            try:
                self.audio_effects_manager = AudioEffectsManager()
                print("ğŸµ éŸ³æ•ˆç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ éŸ³æ•ˆç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.audio_effects_manager = None
        else:
            self.audio_effects_manager = None

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                # å·¥ä½œæ¨¡å¼é€‰æ‹©
                "work_mode": (["ä¼ ç»Ÿè§†é¢‘æ‹¼æ¥", "AIå›¾ç”Ÿè§†é¢‘"], {
                    "default": "AIå›¾ç”Ÿè§†é¢‘",
                    "tooltip": "é€‰æ‹©å·¥ä½œæ¨¡å¼"
                }),

                "audio_list": ("AUDIO_LIST", {
                    "tooltip": "å¯¹åº”çš„éŸ³é¢‘åˆ—è¡¨"
                }),

                # AIæ¨¡å¼ä¸“ç”¨å‚æ•°
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "RunningHub APIå¯†é’¥ï¼ˆAIæ¨¡å¼å¿…éœ€ï¼‰"
                }),
                "scene_video_prompts": ("STRING", {
                    "multiline": True,
                    "default": "åœºæ™¯1ï¼šç¾ä¸½çš„é£æ™¯æ…¢æ…¢å±•å¼€\nåœºæ™¯2ï¼šäººç‰©åœ¨ç”»é¢ä¸­ç§»åŠ¨",
                    "tooltip": "åœºæ™¯å›¾ç”Ÿè§†é¢‘æç¤ºè¯ï¼Œæ¯è¡Œå¯¹åº”ä¸€ä¸ªåœºæ™¯å›¾ç‰‡"
                }),

                # åŸºç¡€å‚æ•°
                "fps": ("INT", {
                    "default": 30,
                    "min": 15,
                    "max": 60,
                    "step": 1,
                    "tooltip": "è¾“å‡ºè§†é¢‘å¸§ç‡"
                }),
                "width": ("INT", {
                    "default": 720,
                    "min": 256,
                    "max": 2048,
                    "step": 8,
                    "tooltip": "è¾“å‡ºè§†é¢‘å®½åº¦"
                }),
                "height": ("INT", {
                    "default": 1280,
                    "min": 256,
                    "max": 2048,
                    "step": 8,
                    "tooltip": "è¾“å‡ºè§†é¢‘é«˜åº¦"
                }),
                "output_format": (["mp4", "avi", "mov"], {
                    "default": "mp4",
                    "tooltip": "è¾“å‡ºè§†é¢‘æ ¼å¼"
                }),
                "quality": (["low", "medium", "high", "ultra"], {
                    "default": "medium",
                    "tooltip": "è§†é¢‘è´¨é‡"
                }),

                # è¿‡æ¸¡æ•ˆæœ
                "transition_type": (["cut", "fade", "dissolve", "slide"], {
                    "default": "fade",
                    "tooltip": "è§†é¢‘ç‰‡æ®µé—´çš„è¿‡æ¸¡æ•ˆæœ"
                }),
                "transition_duration": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 3.0,
                    "step": 0.1,
                    "tooltip": "è¿‡æ¸¡æ•ˆæœæ—¶é•¿ï¼ˆç§’ï¼‰"
                }),

                # éŸ³æ•ˆç³»ç»Ÿ
                "enable_audio_effects": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨éŸ³æ•ˆå¢å¼º"
                }),
                "opening_sound_choice": (["æ— ", "è‡ªåŠ¨é€‰æ‹©", "å²è¯—å¼€åœº", "åº„é‡å¼€åœº", "å¤§æ°”å¼€åœº", "è½»æ¾å¼€åœº", "ç¥ç§˜å¼€åœº", "åŠ¨æ„Ÿå¼€åœº"], {
                    "default": "è‡ªåŠ¨é€‰æ‹©",
                    "tooltip": "å¼€åœºéŸ³æ•ˆé€‰æ‹©"
                }),
                "background_music_choice": (["æ— ", "è‡ªåŠ¨é€‰æ‹©", "å²è¯—èƒŒæ™¯", "åº„é‡èƒŒæ™¯", "å¤§æ°”èƒŒæ™¯", "è½»æ¾èƒŒæ™¯", "ç¥ç§˜èƒŒæ™¯", "åŠ¨æ„ŸèƒŒæ™¯"], {
                    "default": "è‡ªåŠ¨é€‰æ‹©",
                    "tooltip": "èƒŒæ™¯éŸ³ä¹é€‰æ‹©"
                }),
                "ambient_sound_choice": (["æ— ", "è‡ªåŠ¨é€‰æ‹©", "è‡ªç„¶ç¯å¢ƒ", "åŸå¸‚ç¯å¢ƒ", "ç§‘æŠ€ç¯å¢ƒ", "é­”æ³•ç¯å¢ƒ"], {
                    "default": "æ— ",
                    "tooltip": "ç¯å¢ƒéŸ³æ•ˆé€‰æ‹©"
                }),

                # éŸ³é‡æ§åˆ¶
                "background_music_volume": ("FLOAT", {
                    "default": 0.3,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "èƒŒæ™¯éŸ³ä¹éŸ³é‡"
                }),
                "opening_sound_volume": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "å¼€åœºéŸ³æ•ˆéŸ³é‡"
                }),
                "ambient_sound_volume": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "ç¯å¢ƒéŸ³æ•ˆéŸ³é‡"
                }),
                "voice_volume": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "ä¸»éŸ³è½¨éŸ³é‡"
                }),

                # å­—ä½“æ ‡é¢˜ç³»ç»Ÿ
                "title_text": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "tooltip": "æ ‡é¢˜æ–‡å­—ï¼ˆå¯é€‰ï¼‰"
                }),
                "enable_title": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "å¯ç”¨æ ‡é¢˜æ˜¾ç¤º"
                }),
                "title_duration": ("FLOAT", {
                    "default": 3.0,
                    "min": 1.0,
                    "max": 10.0,
                    "step": 0.5,
                    "tooltip": "æ ‡é¢˜æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰"
                }),
                "title_fontsize": ("INT", {
                    "default": 80,
                    "min": 30,
                    "max": 300,
                    "step": 5,
                    "tooltip": "æ ‡é¢˜å­—ä½“å¤§å°"
                }),
                "title_color": (["white", "black", "red", "gold", "blue"], {
                    "default": "white",
                    "tooltip": "æ ‡é¢˜é¢œè‰²"
                }),
                "title_font": (["è‡ªåŠ¨é€‰æ‹©", "Notoæ— è¡¬çº¿-å¸¸è§„", "Notoæ— è¡¬çº¿-ç²—ä½“", "Notoè¡¬çº¿ä½“-ç²—ä½“", "æ–‡æ³‰é©¿æ­£é»‘", "è¶…çº§ç²—ä½“", "è‹±æ–‡ç²—ä½“"], {
                    "default": "è‡ªåŠ¨é€‰æ‹©",
                    "tooltip": "æ ‡é¢˜å­—ä½“"
                }),

                # AIæ¨¡å¼å‚æ•°
                "steps": ("INT", {
                    "default": 6,
                    "min": 4,
                    "max": 20,
                    "step": 1,
                    "tooltip": "AIè§†é¢‘ç”Ÿæˆæ¨ç†æ­¥æ•°"
                }),
                "cfg_scale": ("FLOAT", {
                    "default": 7.5,
                    "min": 1.0,
                    "max": 20.0,
                    "step": 0.5,
                    "tooltip": "CFGç¼©æ”¾ç³»æ•°"
                }),
                "motion_strength": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.1,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "è¿åŠ¨å¼ºåº¦ï¼ˆAIæ¨¡å¼ï¼‰"
                }),
                "max_concurrent": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 5,
                    "tooltip": "AIç”Ÿæˆæœ€å¤§å¹¶å‘æ•°"
                }),
            },
            "optional": {
                # ä¼ ç»Ÿæ¨¡å¼ï¼šç°æœ‰è§†é¢‘ç‰‡æ®µ
                "video_list": ("VIDEO_LIST", {
                    "tooltip": "ä¼ ç»Ÿæ¨¡å¼ï¼šç°æœ‰è§†é¢‘ç‰‡æ®µåˆ—è¡¨"
                }),

                # AIæ¨¡å¼ï¼šå›¾ç‰‡è¾“å…¥
                "images": ("IMAGE", {
                    "tooltip": "AIæ¨¡å¼ï¼šåœºæ™¯å›¾ç‰‡åˆ—è¡¨ï¼ˆä¸å«ä¸»è§’å›¾ï¼‰"
                }),
                "character_image": ("IMAGE", {
                    "tooltip": "AIæ¨¡å¼ï¼šä¸»è§’å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰"
                }),
                "character_video_prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä¸»è§’ï¼šäººç‰©åœ¨ç”»é¢ä¸­è‡ªç„¶ç§»åŠ¨ï¼Œè¡¨æƒ…ç”ŸåŠ¨",
                    "tooltip": "ä¸»è§’å›¾ç”Ÿè§†é¢‘æç¤ºè¯ï¼ˆå•ç‹¬é…ç½®ï¼‰"
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä½è´¨é‡, æ¨¡ç³Š, å˜å½¢, é™æ€",
                    "tooltip": "è´Ÿé¢æç¤ºè¯ï¼ˆAIæ¨¡å¼ï¼‰"
                }),
                "enable_character_intro": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨ä¸»è§’å¼€åœºä»‹ç»"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("video_path", "info")
    FUNCTION = "create_ai_video"
    CATEGORY = "ğŸ¥ Shenglin Video System"

    def create_ai_video(self, work_mode, audio_list, api_key, scene_video_prompts, fps=30,
                       width=720, height=1280, output_format="mp4", quality="medium",
                       transition_type="fade", transition_duration=0.5, enable_audio_effects=True,
                       opening_sound_choice="è‡ªåŠ¨é€‰æ‹©", background_music_choice="è‡ªåŠ¨é€‰æ‹©",
                       ambient_sound_choice="æ— ", background_music_volume=0.3,
                       opening_sound_volume=0.8, ambient_sound_volume=0.5, voice_volume=1.0,
                       title_text="", enable_title=False, title_duration=3.0,
                       title_fontsize=80, title_color="white", title_font="è‡ªåŠ¨é€‰æ‹©",
                       steps=6, cfg_scale=7.5, motion_strength=0.8, max_concurrent=2,
                       video_list=None, images=None, character_image=None,
                       character_video_prompt="ä¸»è§’ï¼šäººç‰©åœ¨ç”»é¢ä¸­è‡ªç„¶ç§»åŠ¨ï¼Œè¡¨æƒ…ç”ŸåŠ¨",
                       negative_prompt="ä½è´¨é‡, æ¨¡ç³Š, å˜å½¢, é™æ€", enable_character_intro=True):
        """
        AIè§†é¢‘åˆ¶ä½œå™¨ä¸»å‡½æ•°
        æ”¯æŒä¼ ç»Ÿè§†é¢‘æ‹¼æ¥å’ŒAIå›¾ç”Ÿè§†é¢‘ä¸¤ç§æ¨¡å¼
        """
        try:
            print(f"ğŸ¬ å¼€å§‹{work_mode}...")

            if not audio_list or len(audio_list) == 0:
                return ("", "é”™è¯¯: éŸ³é¢‘åˆ—è¡¨ä¸ºç©º")

            # æ ¹æ®å·¥ä½œæ¨¡å¼é€‰æ‹©å¤„ç†æµç¨‹
            if work_mode == "AIå›¾ç”Ÿè§†é¢‘":
                return self._handle_ai_mode(
                    audio_list, api_key, scene_video_prompts, fps, width, height,
                    output_format, quality, transition_type, transition_duration,
                    enable_audio_effects, opening_sound_choice, background_music_choice,
                    ambient_sound_choice, background_music_volume, opening_sound_volume,
                    ambient_sound_volume, voice_volume, title_text, enable_title,
                    title_duration, title_fontsize, title_color, title_font,
                    steps, cfg_scale, motion_strength, max_concurrent,
                    images, character_image, character_video_prompt,
                    negative_prompt, enable_character_intro
                )
            else:
                # ä¼ ç»Ÿæ¨¡å¼ï¼šåŸºäºç°æœ‰è§†é¢‘ç‰‡æ®µ
                if not video_list or len(video_list) == 0:
                    return ("", "é”™è¯¯: ä¼ ç»Ÿæ¨¡å¼éœ€è¦æä¾›è§†é¢‘ç‰‡æ®µåˆ—è¡¨")

                return self._handle_traditional_mode(
                    video_list, audio_list, fps, width, height, output_format, quality,
                    transition_type, transition_duration, enable_audio_effects,
                    opening_sound_choice, background_music_choice, ambient_sound_choice,
                    background_music_volume, opening_sound_volume, ambient_sound_volume,
                    voice_volume, title_text, enable_title, title_duration,
                    title_fontsize, title_color, title_font
                )

        except Exception as e:
            error_msg = f"AIè§†é¢‘åˆ¶ä½œå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return ("", error_msg)

    def _handle_traditional_mode(self, video_list, audio_list, fps, width, height,
                               output_format, quality, transition_type, transition_duration,
                               enable_audio_effects, opening_sound_choice, background_music_choice,
                               ambient_sound_choice, background_music_volume, opening_sound_volume,
                               ambient_sound_volume, voice_volume, title_text, enable_title,
                               title_duration, title_fontsize, title_color, title_font):
        """ä¼ ç»Ÿæ¨¡å¼ï¼šåŸºäºç°æœ‰è§†é¢‘ç‰‡æ®µçš„åˆæˆ"""
        try:
            print(f"ğŸ“‹ è¾“å…¥ä¿¡æ¯: {len(video_list)}ä¸ªè§†é¢‘ç‰‡æ®µ, {len(audio_list)}ä¸ªéŸ³é¢‘æ®µ")

            # è®¡ç®—éŸ³é¢‘æ—¶é•¿
            audio_durations = []
            for i, audio_dict in enumerate(audio_list):
                waveform = audio_dict["waveform"]
                if len(waveform.shape) == 3:
                    waveform = waveform[0]
                sample_rate = audio_dict["sample_rate"]
                duration = waveform.shape[1] / sample_rate
                audio_durations.append(duration)
                print(f"ğŸµ éŸ³é¢‘{i+1}: {duration:.2f}ç§’")

            total_duration = sum(audio_durations)

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            import time
            timestamp = str(int(time.time()))
            output_filename = f"video_from_videos_{timestamp}.{output_format}"
            video_path = os.path.join(self.output_dir, output_filename)

            # ç¬¬ä¸€æ­¥ï¼šæ‹¼æ¥è§†é¢‘ç‰‡æ®µ
            print("ğŸ”— æ‹¼æ¥è§†é¢‘ç‰‡æ®µ...")
            concatenated_video = self._concatenate_videos(video_list, transition_type, transition_duration, fps)

            if not concatenated_video:
                return ("", "é”™è¯¯: è§†é¢‘æ‹¼æ¥å¤±è´¥")

            # ç¬¬äºŒæ­¥ï¼šè°ƒæ•´è§†é¢‘å°ºå¯¸å’Œæ—¶é•¿
            print("ğŸ“ è°ƒæ•´è§†é¢‘å°ºå¯¸å’ŒåŒæ­¥...")
            resized_video = self._resize_and_sync_video(concatenated_video, width, height, total_duration, fps)

            # ç¬¬ä¸‰æ­¥ï¼šåˆæˆéŸ³é¢‘
            print("ğŸµ åˆæˆéŸ³é¢‘è½¨é“...")
            combined_audio_path = self._compose_enhanced_audio(
                audio_list, audio_durations, enable_audio_effects,
                opening_sound_choice, background_music_choice, ambient_sound_choice,
                background_music_volume, opening_sound_volume, ambient_sound_volume, voice_volume
            )

            # ç¬¬å››æ­¥ï¼šåˆæˆæœ€ç»ˆè§†é¢‘
            print("ğŸ¬ åˆæˆæœ€ç»ˆè§†é¢‘...")
            final_video = self._combine_video_audio_with_title(
                resized_video, combined_audio_path, video_path, quality,
                title_text, enable_title, title_duration, title_fontsize, title_color, title_font
            )

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files([concatenated_video, resized_video, combined_audio_path])

            if not final_video:
                return ("", "é”™è¯¯: æœ€ç»ˆè§†é¢‘åˆæˆå¤±è´¥")

            # ç”Ÿæˆä¿¡æ¯
            info = (f"åŸºäºè§†é¢‘çš„è§†é¢‘åˆæˆå®Œæˆ\\n"
                   f"è§†é¢‘ç‰‡æ®µ: {len(video_list)}ä¸ª\\n"
                   f"éŸ³é¢‘æ®µæ•°: {len(audio_list)}\\n"
                   f"æ€»æ—¶é•¿: {total_duration:.2f}ç§’\\n"
                   f"åˆ†è¾¨ç‡: {width}x{height}\\n"
                   f"å¸§ç‡: {fps}fps\\n"
                   f"è¿‡æ¸¡æ•ˆæœ: {transition_type}\\n"
                   f"è¾“å‡º: {output_filename}")

            print(f"âœ… åŸºäºè§†é¢‘çš„åˆæˆå®Œæˆ: {video_path}")
            return (video_path, info)

        except Exception as e:
            error_msg = f"åŸºäºè§†é¢‘çš„åˆæˆå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return ("", error_msg)

    def _handle_ai_mode(self, audio_list, api_key, scene_video_prompts, fps, width, height,
                       output_format, quality, transition_type, transition_duration,
                       enable_audio_effects, opening_sound_choice, background_music_choice,
                       ambient_sound_choice, background_music_volume, opening_sound_volume,
                       ambient_sound_volume, voice_volume, title_text, enable_title,
                       title_duration, title_fontsize, title_color, title_font,
                       steps, cfg_scale, motion_strength, max_concurrent,
                       images, character_image, character_video_prompt,
                       negative_prompt, enable_character_intro):
        """AIæ¨¡å¼ï¼šå›¾ç‰‡é€šè¿‡RunningHub Wan2.2ç”Ÿæˆè§†é¢‘åæ‹¼æ¥"""
        try:
            if not api_key.strip():
                return ("", "é”™è¯¯: AIæ¨¡å¼éœ€è¦æä¾›RunningHub APIå¯†é’¥")

            # è§£æåœºæ™¯è§†é¢‘æç¤ºè¯
            scene_prompts = [line.strip() for line in scene_video_prompts.strip().split('\n') if line.strip()]
            if not scene_prompts:
                return ("", "é”™è¯¯: åœºæ™¯è§†é¢‘æç¤ºè¯ä¸èƒ½ä¸ºç©º")

            print(f"ğŸ¬ AIæ¨¡å¼: {len(scene_prompts)}ä¸ªåœºæ™¯æç¤ºè¯, {len(audio_list)}ä¸ªéŸ³é¢‘")

            # æ„å»ºè¾“å…¥å›¾ç‰‡åˆ—è¡¨ï¼ˆä¸»è§’å›¾+åœºæ™¯å›¾ï¼‰
            all_images = []
            all_prompts = []

            # å¤„ç†ä¸»è§’å›¾ï¼ˆå¦‚æœæœ‰ï¼‰
            if character_image is not None and enable_character_intro:
                if len(character_image.shape) == 4:
                    # æ‰¹é‡å›¾ç‰‡ï¼Œå–ç¬¬ä¸€å¼ ä½œä¸ºä¸»è§’
                    char_img = character_image[0]
                else:
                    char_img = character_image
                all_images.append(char_img)
                all_prompts.append(character_video_prompt.strip())
                print("ğŸ‘¤ æ·»åŠ ä¸»è§’å›¾ç‰‡")

            # å¤„ç†åœºæ™¯å›¾ç‰‡
            if images is not None:
                if len(images.shape) == 4:
                    # æ‰¹é‡å›¾ç‰‡
                    scene_count = min(len(scene_prompts), images.shape[0])
                    for i in range(scene_count):
                        all_images.append(images[i])
                        prompt_idx = min(i, len(scene_prompts) - 1)
                        all_prompts.append(scene_prompts[prompt_idx])
                    print(f"ğŸ–¼ï¸ æ·»åŠ  {scene_count} å¼ åœºæ™¯å›¾ç‰‡")
                else:
                    # å•å¼ åœºæ™¯å›¾ç‰‡
                    all_images.append(images)
                    all_prompts.append(scene_prompts[0] if scene_prompts else "åœºæ™¯è§†é¢‘")
                    print("ğŸ–¼ï¸ æ·»åŠ  1 å¼ åœºæ™¯å›¾ç‰‡")

            if not all_images:
                return ("", "é”™è¯¯: æœªæä¾›ä»»ä½•å›¾ç‰‡ï¼ˆè¯·æä¾›åœºæ™¯å›¾ç‰‡æˆ–ä¸»è§’å›¾ç‰‡ï¼‰")

            # ç¡®ä¿éŸ³é¢‘å’Œå›¾ç‰‡æ•°é‡åŒ¹é…
            if len(all_images) != len(audio_list):
                return ("", f"é”™è¯¯: å›¾ç‰‡æ•°é‡({len(all_images)})ä¸éŸ³é¢‘æ•°é‡({len(audio_list)})ä¸åŒ¹é…")

            # è°ƒç”¨RunningHub Wan2.2 APIç”Ÿæˆè§†é¢‘
            print("ğŸš€ å¼€å§‹è°ƒç”¨RunningHub Wan2.2 APIç”Ÿæˆè§†é¢‘...")
            video_paths = self._generate_videos_with_runninghub(
                all_images, all_prompts, audio_list, api_key, steps, cfg_scale,
                motion_strength, max_concurrent, negative_prompt
            )

            if not video_paths or not any(video_paths):
                return ("", "é”™è¯¯: RunningHub APIè§†é¢‘ç”Ÿæˆå¤±è´¥")

            print(f"âœ… æˆåŠŸç”Ÿæˆ {len([p for p in video_paths if p])} ä¸ªè§†é¢‘ç‰‡æ®µ")

            # ä½¿ç”¨ç”Ÿæˆçš„è§†é¢‘è¿›è¡Œåç»­åˆæˆï¼ˆè°ƒç”¨ä¼ ç»Ÿæ¨¡å¼é€»è¾‘ï¼‰
            return self._handle_traditional_mode(
                video_paths, audio_list, fps, width, height, output_format, quality,
                transition_type, transition_duration, enable_audio_effects,
                opening_sound_choice, background_music_choice, ambient_sound_choice,
                background_music_volume, opening_sound_volume, ambient_sound_volume,
                voice_volume, title_text, enable_title, title_duration,
                title_fontsize, title_color, title_font
            )

        except Exception as e:
            error_msg = f"AIæ¨¡å¼å¤„ç†å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return ("", error_msg)

    def _concatenate_videos(self, video_list, transition_type, transition_duration, fps):
        """æ‹¼æ¥è§†é¢‘ç‰‡æ®µ"""
        try:
            temp_video = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)
            temp_video.close()

            if transition_type == "cut":
                # ç›´æ¥æ‹¼æ¥ï¼Œæ— è¿‡æ¸¡
                concat_list = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
                for video_path in video_list:
                    concat_list.write(f"file '{video_path}'\\n")
                concat_list.close()

                cmd = ['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', concat_list.name,
                       '-c', 'copy', temp_video.name]

                os.unlink(concat_list.name)
            else:
                # å¸¦è¿‡æ¸¡æ•ˆæœçš„æ‹¼æ¥
                cmd = ['ffmpeg', '-y']

                # æ·»åŠ æ‰€æœ‰è¾“å…¥è§†é¢‘
                for video_path in video_list:
                    cmd.extend(['-i', video_path])

                # æ„å»ºè¿‡æ¸¡æ»¤é•œ
                if transition_type == "fade":
                    filter_complex = self._build_fade_filter(len(video_list), transition_duration)
                elif transition_type == "dissolve":
                    filter_complex = self._build_dissolve_filter(len(video_list), transition_duration)
                elif transition_type == "slide":
                    filter_complex = self._build_slide_filter(len(video_list), transition_duration)
                else:
                    filter_complex = self._build_fade_filter(len(video_list), transition_duration)

                cmd.extend(['-filter_complex', filter_complex, temp_video.name])

            subprocess.run(cmd, check=True, capture_output=True)
            return temp_video.name

        except Exception as e:
            print(f"âŒ è§†é¢‘æ‹¼æ¥å¤±è´¥: {e}")
            return None

    def _build_fade_filter(self, video_count, transition_duration):
        """æ„å»ºæ·¡å…¥æ·¡å‡ºè¿‡æ¸¡æ»¤é•œ"""
        filter_parts = []

        for i in range(video_count):
            if i == 0:
                # ç¬¬ä¸€ä¸ªè§†é¢‘
                filter_parts.append(f"[{i}:v]fade=t=out:st=0:d={transition_duration}[v{i}]")
            elif i == video_count - 1:
                # æœ€åä¸€ä¸ªè§†é¢‘
                filter_parts.append(f"[{i}:v]fade=t=in:st=0:d={transition_duration}[v{i}]")
            else:
                # ä¸­é—´è§†é¢‘
                filter_parts.append(f"[{i}:v]fade=t=in:st=0:d={transition_duration},fade=t=out:st=0:d={transition_duration}[v{i}]")

        # æ‹¼æ¥æ‰€æœ‰è§†é¢‘
        concat_inputs = "".join([f"[v{i}]" for i in range(video_count)])
        filter_parts.append(f"{concat_inputs}concat=n={video_count}:v=1:a=0[outv]")

        return ";".join(filter_parts)

    def _build_dissolve_filter(self, video_count, transition_duration):
        """æ„å»ºæº¶è§£è¿‡æ¸¡æ»¤é•œ"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨fadeä½œä¸ºæº¶è§£æ•ˆæœ
        return self._build_fade_filter(video_count, transition_duration)

    def _build_slide_filter(self, video_count, transition_duration):
        """æ„å»ºæ»‘åŠ¨è¿‡æ¸¡æ»¤é•œ"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨fadeä½œä¸ºæ»‘åŠ¨æ•ˆæœ
        return self._build_fade_filter(video_count, transition_duration)

    def _resize_and_sync_video(self, video_path, width, height, target_duration, fps):
        """è°ƒæ•´è§†é¢‘å°ºå¯¸å’ŒåŒæ­¥æ—¶é•¿"""
        try:
            temp_video = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)
            temp_video.close()

            cmd = [
                'ffmpeg', '-y', '-i', video_path,
                '-vf', f'scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2',
                '-t', str(target_duration),
                '-r', str(fps),
                '-c:v', 'libx264',
                '-preset', 'medium',
                temp_video.name
            ]

            subprocess.run(cmd, check=True, capture_output=True)
            return temp_video.name

        except Exception as e:
            print(f"âŒ è§†é¢‘è°ƒæ•´å¤±è´¥: {e}")
            return None

    def _compose_enhanced_audio(self, audio_list, durations, enable_audio_effects,
                              opening_sound_choice, background_music_choice, ambient_sound_choice,
                              background_music_volume, opening_sound_volume, ambient_sound_volume, voice_volume):
        """å¢å¼ºéŸ³é¢‘åˆæˆï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰"""
        try:
            # åˆæˆä¸»éŸ³è½¨
            main_audio_path = self._combine_audio(audio_list)

            if not enable_audio_effects or not self.audio_effects_manager:
                return main_audio_path

            # åº”ç”¨éŸ³æ•ˆå¢å¼º
            enhanced_audio = self.audio_effects_manager.enhance_audio_with_effects(
                main_audio_path, durations,
                opening_sound=opening_sound_choice,
                background_music=background_music_choice,
                ambient_sound=ambient_sound_choice,
                bg_volume=background_music_volume,
                opening_volume=opening_sound_volume,
                ambient_volume=ambient_sound_volume,
                voice_volume=voice_volume
            )

            return enhanced_audio if enhanced_audio else main_audio_path

        except Exception as e:
            print(f"âŒ éŸ³é¢‘åˆæˆå¤±è´¥: {e}")
            return self._combine_audio(audio_list)

    def _combine_audio(self, audio_list):
        """æ‹¼æ¥éŸ³é¢‘"""
        waveforms = []
        sample_rate = None

        for audio_dict in audio_list:
            waveform = audio_dict["waveform"]
            if len(waveform.shape) == 3:
                waveform = waveform[0]
            waveforms.append(waveform)
            sample_rate = audio_dict["sample_rate"]

        combined_waveform = torch.cat(waveforms, dim=1)

        temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
        torchaudio.save(temp_file.name, combined_waveform, sample_rate)
        temp_file.close()

        return temp_file.name

    def _combine_video_audio_with_title(self, video_path, audio_path, output_path, quality,
                                      title_text, enable_title, title_duration, title_fontsize,
                                      title_color, title_font):
        """åˆæˆè§†é¢‘ã€éŸ³é¢‘å’Œæ ‡é¢˜"""
        try:
            # è´¨é‡è®¾ç½®
            quality_settings = {
                "low": ["-crf", "28", "-preset", "fast"],
                "medium": ["-crf", "23", "-preset", "medium"],
                "high": ["-crf", "18", "-preset", "slow"],
                "ultra": ["-crf", "15", "-preset", "slower"]
            }

            cmd = ['ffmpeg', '-y', '-i', video_path, '-i', audio_path]

            # æ·»åŠ æ–‡å­—æ»¤é•œï¼ˆå¦‚æœå¯ç”¨æ ‡é¢˜ï¼‰
            if enable_title and title_text.strip():
                font_path = self._get_font_path(title_font)
                title_text_escaped = title_text.replace(":", "\\:")

                if font_path:
                    text_filter = f"drawtext=text='{title_text_escaped}':fontfile='{font_path}':fontsize={title_fontsize}:fontcolor={title_color}:x=(w-text_w)/2:y=(h-text_h)/2:enable='between(t,0,{title_duration})'"
                else:
                    text_filter = f"drawtext=text='{title_text_escaped}':fontsize={title_fontsize}:fontcolor={title_color}:x=(w-text_w)/2:y=(h-text_h)/2:enable='between(t,0,{title_duration})'"

                cmd.extend(['-vf', text_filter])
                print(f"ğŸ“ æ·»åŠ æ ‡é¢˜: '{title_text}' (æ˜¾ç¤º{title_duration}ç§’)")

            # æ·»åŠ è´¨é‡è®¾ç½®
            cmd.extend(quality_settings[quality])
            cmd.extend(['-c:a', 'aac', '-b:a', '192k', output_path])

            subprocess.run(cmd, check=True, capture_output=True)
            return True

        except Exception as e:
            print(f"âŒ æœ€ç»ˆåˆæˆå¤±è´¥: {e}")
            return False

    def _get_font_path(self, font_name):
        """è·å–å­—ä½“è·¯å¾„ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰"""
        try:
            # å¯¼å…¥å­—ä½“æ˜ å°„é€»è¾‘
            font_name_mapping = {
                "è‡ªåŠ¨é€‰æ‹©": "auto",
                "Notoæ— è¡¬çº¿-å¸¸è§„": "noto_cjk_regular",
                "Notoæ— è¡¬çº¿-ç²—ä½“": "noto_cjk_bold",
                "Notoè¡¬çº¿ä½“-ç²—ä½“": "noto_serif_cjk_bold",
                "æ–‡æ³‰é©¿æ­£é»‘": "wqy_zenhei",
                "è¶…çº§ç²—ä½“": "nimbus_sans_bold",
                "è‹±æ–‡ç²—ä½“": "noto_serif_bold"
            }

            if font_name in font_name_mapping:
                font_name = font_name_mapping[font_name]

            # è·å–å†…ç½®å­—ä½“åŒ…è·¯å¾„
            bundled_fonts_dir = self._get_bundled_fonts_dir()
            if not bundled_fonts_dir:
                return None

            if font_name == "auto":
                # è‡ªåŠ¨é€‰æ‹©ï¼ˆç²—ä½“ä¼˜å…ˆï¼‰
                priority_fonts = [
                    os.path.join(bundled_fonts_dir, "NotoSansCJK-Bold.ttc"),
                    os.path.join(bundled_fonts_dir, "NotoSerifCJK-Bold.ttc"),
                    os.path.join(bundled_fonts_dir, "wqy-zenhei.ttc"),
                    os.path.join(bundled_fonts_dir, "NotoSansCJK-Regular.ttc"),
                ]
                for font_path in priority_fonts:
                    if os.path.exists(font_path):
                        return font_path

            # å­—ä½“æ˜ å°„
            font_mapping = {
                "noto_cjk_regular": os.path.join(bundled_fonts_dir, "NotoSansCJK-Regular.ttc"),
                "noto_cjk_bold": os.path.join(bundled_fonts_dir, "NotoSansCJK-Bold.ttc"),
                "noto_serif_cjk_bold": os.path.join(bundled_fonts_dir, "NotoSerifCJK-Bold.ttc"),
                "wqy_zenhei": os.path.join(bundled_fonts_dir, "wqy-zenhei.ttc"),
                "nimbus_sans_bold": os.path.join(bundled_fonts_dir, "NimbusSans-Bold.otf"),
                "noto_serif_bold": os.path.join(bundled_fonts_dir, "NotoSerif-Bold.ttf"),
            }

            if font_name in font_mapping:
                font_path = font_mapping[font_name]
                if os.path.exists(font_path):
                    return font_path

            return None

        except Exception as e:
            print(f"âš ï¸ å­—ä½“è·å–å¤±è´¥: {e}")
            return None

    def _get_bundled_fonts_dir(self):
        """è·å–å†…ç½®å­—ä½“åŒ…ç›®å½•"""
        try:
            current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            fonts_dir = os.path.join(current_dir, "fonts")
            return fonts_dir if os.path.exists(fonts_dir) else None
        except:
            return None

    def _cleanup_temp_files(self, file_paths):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for file_path in file_paths:
            if file_path and os.path.exists(file_path):
                try:
                    os.unlink(file_path)
                except:
                    pass

    def _generate_videos_with_runninghub(self, images, prompts, audio_list, api_key,
                                       steps, cfg_scale, motion_strength, max_concurrent, negative_prompt):
        """ä½¿ç”¨RunningHub Wan2.2 APIç”Ÿæˆè§†é¢‘"""
        try:
            # è·å–éŸ³é¢‘æ—¶é•¿åˆ—è¡¨
            audio_durations = self._get_audio_durations(audio_list)

            # è½¬æ¢å›¾ç‰‡æ ¼å¼
            image_list = []
            for img_tensor in images:
                if isinstance(img_tensor, torch.Tensor):
                    img_array = img_tensor.cpu().numpy()
                    if img_array.max() <= 1.0:
                        img_array = (img_array * 255).astype(np.uint8)
                    image_list.append(Image.fromarray(img_array))
                else:
                    image_list.append(img_tensor)

            print(f"ğŸ¬ å‡†å¤‡ç”Ÿæˆ {len(image_list)} ä¸ªè§†é¢‘ç‰‡æ®µ")

            # å¼‚æ­¥è°ƒç”¨API
            try:
                loop = asyncio.get_running_loop()
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self._batch_generate_videos_async(
                        image_list, prompts, audio_durations, api_key, steps, cfg_scale,
                        motion_strength, max_concurrent, negative_prompt
                    ))
                    results = future.result()
            except RuntimeError as e:
                if "There is no current event loop" in str(e):
                    results = asyncio.run(
                        self._batch_generate_videos_async(
                            image_list, prompts, audio_durations, api_key, steps, cfg_scale,
                            motion_strength, max_concurrent, negative_prompt
                        )
                    )
                else:
                    loop = asyncio.get_event_loop()
                    results = loop.run_until_complete(
                        self._batch_generate_videos_async(
                            image_list, prompts, audio_durations, api_key, steps, cfg_scale,
                            motion_strength, max_concurrent, negative_prompt
                        )
                    )

            # æå–è§†é¢‘è·¯å¾„
            video_paths = []
            for result in results:
                if result and result.get('success'):
                    video_paths.append(result.get('video_path', ''))
                else:
                    video_paths.append('')

            return video_paths

        except Exception as e:
            print(f"âŒ RunningHub APIè°ƒç”¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _get_audio_durations(self, audio_list):
        """è·å–éŸ³é¢‘æ—¶é•¿åˆ—è¡¨"""
        durations = []
        for audio_dict in audio_list:
            waveform = audio_dict["waveform"]
            if len(waveform.shape) == 3:
                waveform = waveform[0]
            sample_rate = audio_dict["sample_rate"]
            duration = waveform.shape[1] / sample_rate
            durations.append(float(duration))
        return durations

    async def _batch_generate_videos_async(self, images, prompts, audio_durations, api_key,
                                         steps, cfg_scale, motion_strength, max_concurrent, negative_prompt):
        """å¼‚æ­¥æ‰¹é‡ç”Ÿæˆè§†é¢‘"""
        semaphore = asyncio.Semaphore(max_concurrent)
        tasks = []
        fps = 16  # Wan2.2å›ºå®šå¸§ç‡

        for i, (image, prompt, duration) in enumerate(zip(images, prompts, audio_durations)):
            frames = max(25, min(200, int(duration * fps)))  # æ ¹æ®éŸ³é¢‘æ—¶é•¿è®¡ç®—å¸§æ•°

            task = asyncio.create_task(
                self._generate_single_video_async(
                    semaphore, i, image, prompt, frames, api_key, steps,
                    cfg_scale, motion_strength, negative_prompt
                )
            )
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)
        return results

    async def _generate_single_video_async(self, semaphore, index, image, prompt, frames,
                                         api_key, steps, cfg_scale, motion_strength, negative_prompt):
        """å¼‚æ­¥ç”Ÿæˆå•ä¸ªè§†é¢‘"""
        async with semaphore:
            try:
                print(f"ğŸ¬ ç”Ÿæˆè§†é¢‘ {index+1}: {frames}å¸§, {prompt[:30]}...")

                # è½¬æ¢å›¾ç‰‡ä¸ºbase64
                buffer = io.BytesIO()
                image.save(buffer, format='PNG')
                image_b64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

                # ç”Ÿæˆéšæœºç§å­
                seed = int(time.time() * 1000) % 2147483647

                # æ„å»ºAPIè¯·æ±‚å‚æ•°
                workflow_id = "1968308523518046210"
                node_list = [
                    {
                        "nodeId": 1,
                        "type": "input_image",
                        "data": {
                            "image": image_b64,
                            "format": "png"
                        }
                    },
                    {
                        "nodeId": 2,
                        "type": "text_prompt",
                        "data": {
                            "text": prompt
                        }
                    },
                    {
                        "nodeId": 3,
                        "type": "video_params",
                        "data": {
                            "frames": frames,
                            "steps": steps,
                            "cfg_scale": cfg_scale,
                            "seed": seed,
                            "motion_strength": motion_strength
                        }
                    }
                ]

                if negative_prompt.strip():
                    node_list.append({
                        "nodeId": 4,
                        "type": "negative_prompt",
                        "data": {
                            "text": negative_prompt.strip()
                        }
                    })

                payload = {
                    "apiKey": api_key,
                    "workflowId": workflow_id,
                    "nodeInfoList": node_list
                }

                # å‘é€APIè¯·æ±‚
                ssl_context = ssl.create_default_context()
                ssl_context.check_hostname = False
                ssl_context.verify_mode = ssl.CERT_NONE

                connector = aiohttp.TCPConnector(ssl=ssl_context)
                timeout = aiohttp.ClientTimeout(total=1200)

                async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
                    async with session.post(
                        'https://api.runninghub.cn/api/v1/workflows/run',
                        headers={
                            'Content-Type': 'application/json',
                            'User-Agent': 'ComfyUI-AIVideoComposer/1.0'
                        },
                        json=payload
                    ) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.status} - {error_text}")

                        result = await response.json()
                        if not result.get('success', False):
                            error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                            raise Exception(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {error_msg}")

                        # è·å–è§†é¢‘URLå¹¶ä¸‹è½½
                        video_data = result.get('data', {})
                        video_url = video_data.get('videoUrl') or video_data.get('output_video')

                        if not video_url:
                            raise Exception("è§†é¢‘URLä¸ºç©º")

                        video_path = await self._download_video_async(session, video_url, prompt, index)

                        print(f"âœ… è§†é¢‘ {index+1} ç”ŸæˆæˆåŠŸ: {video_path}")
                        return {
                            "success": True,
                            "video_path": video_path,
                            "frames": frames,
                            "prompt": prompt
                        }

            except Exception as e:
                print(f"âŒ è§†é¢‘ {index+1} ç”Ÿæˆå¤±è´¥: {e}")
                return {"success": False, "error": str(e)}

    async def _download_video_async(self, session, video_url, prompt, index):
        """å¼‚æ­¥ä¸‹è½½è§†é¢‘"""
        try:
            safe_prompt = "".join(c for c in prompt if c.isalnum() or c in (' ', '-', '_'))[:30]
            timestamp = int(time.time())
            filename = f"ai_video_{index+1}_{timestamp}_{safe_prompt[:10]}.mp4"
            video_path = os.path.join(self.output_dir, filename)

            async with session.get(video_url) as response:
                if response.status == 200:
                    with open(video_path, 'wb') as f:
                        async for chunk in response.content.iter_chunked(8192):
                            f.write(chunk)
                    return video_path
                else:
                    raise Exception(f"ä¸‹è½½å¤±è´¥: {response.status}")

        except Exception as e:
            print(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")
            return video_url  # è¿”å›åŸå§‹URLä½œä¸ºå¤‡é€‰

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "AIVideoComposer": AIVideoComposer
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AIVideoComposer": "ğŸ¬ AIè§†é¢‘åˆ¶ä½œå™¨"
}