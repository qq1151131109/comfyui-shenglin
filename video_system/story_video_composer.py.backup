"""
æ•…äº‹è§†é¢‘åˆæˆèŠ‚ç‚¹ - æœ€ç»ˆè§†é¢‘åˆæˆå™¨
StoryVideoComposer: æ•´åˆæ‰€æœ‰è½¨é“è¿›è¡Œæœ€ç»ˆè§†é¢‘åˆæˆ
"""

import json
import os
import tempfile
from typing import List, Dict, Any, Tuple
import torch

class StoryVideoComposer:
    """
    æœ€ç»ˆè§†é¢‘åˆæˆå™¨
    - 5è½¨é“éŸ³é¢‘åˆæˆï¼šé…éŸ³+èƒŒæ™¯éŸ³ä¹+å¼€åœºéŸ³æ•ˆ
    - å¤šå±‚è§†é¢‘åˆæˆï¼šåœºæ™¯å›¾+ä¸»è§’å›¾+åŠ¨ç”»
    - åŒå­—å¹•ç³»ç»Ÿï¼šä¸»å­—å¹•+æ ‡é¢˜å­—å¹•
    - è¾“å‡º1440x1080è§†é¢‘
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "audio_timeline": ("STRING", {"multiline": True}),      # éŸ³é¢‘æ—¶é—´è½´
                "video_timeline": ("STRING", {"multiline": True}),      # è§†é¢‘æ—¶é—´è½´  
                "subtitle_timeline": ("STRING", {"multiline": True}),   # å­—å¹•æ—¶é—´è½´
                "title_timeline": ("STRING", {"multiline": True}),      # æ ‡é¢˜æ—¶é—´è½´
                "animation_data": ("STRING", {"multiline": True}),      # åŠ¨ç”»æ•°æ®
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("video_path", "composition_data")
    
    FUNCTION = "compose_video"
    CATEGORY = "ğŸ”¥ Shenglin/è§†é¢‘å¤„ç†"
    
    def compose_video(self, audio_timeline: str, video_timeline: str, subtitle_timeline: str,
                     title_timeline: str, animation_data: str) -> Tuple[str, str]:
        """åˆæˆæœ€ç»ˆè§†é¢‘"""
        try:
            # è§£æè¾“å…¥æ•°æ®
            audio_data = json.loads(audio_timeline)
            video_data = json.loads(video_timeline) 
            subtitle_data = json.loads(subtitle_timeline)
            title_data = json.loads(title_timeline)
            animation_config = json.loads(animation_data)
            
            # åˆ›å»ºåˆæˆé…ç½®
            composition_config = self._build_composition_config(
                audio_data, video_data, subtitle_data, title_data, animation_config
            )
            
            # æ‰§è¡Œè§†é¢‘åˆæˆ
            output_video_path = self._execute_composition(composition_config)
            
            return (output_video_path, json.dumps(composition_config, ensure_ascii=False))
            
        except Exception as e:
            print(f"VideoComposer error: {e}")
            # è¿”å›é”™è¯¯å ä½ç¬¦
            return ("", "{}")
    
    def _build_composition_config(self, audio_data: List[Dict], video_data: List[Dict], 
                                 subtitle_data: List[Dict], title_data: List[Dict], 
                                 animation_config: Dict) -> Dict:
        """æ„å»ºå®Œæ•´çš„åˆæˆé…ç½®"""
        
        # è®¡ç®—æ€»æ—¶é•¿
        max_audio_time = max([track["end"] for track in audio_data if "end" in track], default=0)
        max_video_time = max([track["end"] for track in video_data if "end" in track], default=0)
        total_duration = max(max_audio_time, max_video_time)
        
        return {
            "project_settings": {
                "width": 1440,
                "height": 1080,
                "fps": 30,
                "duration_microseconds": total_duration,
                "format": "mp4"
            },
            
            "audio_tracks": self._organize_audio_tracks(audio_data),
            "video_tracks": self._organize_video_tracks(video_data, animation_config),
            "subtitle_tracks": self._organize_subtitle_tracks(subtitle_data, title_data),
            
            "composition_layers": [
                {"name": "background_scenes", "type": "video", "z_index": 1},
                {"name": "character_overlay", "type": "video", "z_index": 2},
                {"name": "main_subtitles", "type": "text", "z_index": 3},
                {"name": "title_overlay", "type": "text", "z_index": 4}
            ],
            
            "export_settings": {
                "codec": "h264",
                "bitrate": "8000k",
                "audio_codec": "aac",
                "audio_bitrate": "192k"
            }
        }
    
    def _organize_audio_tracks(self, audio_data: List[Dict]) -> Dict[str, List[Dict]]:
        """ç»„ç»‡éŸ³é¢‘è½¨é“"""
        audio_tracks = {
            "main_voice": [],
            "background_music": [],
            "sound_effects": []
        }
        
        for track in audio_data:
            track_type = track.get("track", "")
            
            if track_type == "main_audio":
                audio_tracks["main_voice"].append({
                    "url": track["audio_url"],
                    "start": track["start"],
                    "end": track["end"],
                    "volume": track.get("volume", 1.0),
                    "fade_in": 100000,  # 0.1ç§’æ·¡å…¥
                    "fade_out": 100000  # 0.1ç§’æ·¡å‡º
                })
                
            elif track_type == "background_music":
                audio_tracks["background_music"].append({
                    "url": track["audio_url"],
                    "start": track["start"],
                    "end": track["end"],
                    "volume": track.get("volume", 0.3),
                    "loop": True
                })
                
            elif track_type == "opening_sound":
                audio_tracks["sound_effects"].append({
                    "url": track["audio_url"],
                    "start": track["start"],
                    "end": track["end"],
                    "volume": track.get("volume", 0.8)
                })
        
        return audio_tracks
    
    def _organize_video_tracks(self, video_data: List[Dict], animation_config: Dict) -> Dict[str, List[Dict]]:
        """ç»„ç»‡è§†é¢‘è½¨é“"""
        video_tracks = {
            "background_scenes": [],
            "character_overlay": []
        }
        
        for track in video_data:
            track_type = track.get("track", "")
            
            # æŸ¥æ‰¾å¯¹åº”çš„åŠ¨ç”»é…ç½®
            animations = self._find_animations_for_track(track, animation_config)
            
            track_config = {
                "image_url": track["image_url"],
                "start": track["start"],
                "end": track["end"],
                "width": track.get("width", 1440),
                "height": track.get("height", 1080),
                "scale_x": track.get("scale_x", 1.0),
                "scale_y": track.get("scale_y", 1.0),
                "layer": track.get("layer", 1),
                "animations": animations
            }
            
            if track_type == "scenes":
                video_tracks["background_scenes"].append(track_config)
            elif track_type == "character":
                video_tracks["character_overlay"].append(track_config)
        
        return video_tracks
    
    def _find_animations_for_track(self, video_track: Dict, animation_config: Dict) -> List[Dict]:
        """ä¸ºè§†é¢‘è½¨é“æŸ¥æ‰¾å¯¹åº”çš„åŠ¨ç”»é…ç½®"""
        animations = []
        keyframes = animation_config.get("keyframes", [])
        
        track_type = video_track.get("track", "")
        track_start = video_track.get("start", 0)
        
        for keyframe in keyframes:
            segment_id = keyframe.get("segment_id", "")
            keyframe_time = keyframe.get("absolute_time", 0)
            
            # æ£€æŸ¥åŠ¨ç”»æ˜¯å¦å±äºå½“å‰è½¨é“
            if ((track_type == "character" and "character" in segment_id) or
                (track_type == "scenes" and "scene" in segment_id)) and \
               (track_start <= keyframe_time < video_track.get("end", 0)):
                
                animations.append({
                    "property": keyframe.get("property", "UNIFORM_SCALE"),
                    "time": keyframe.get("offset", 0),  # ç›¸å¯¹æ—¶é—´
                    "value": keyframe.get("value", 1.0),
                    "easing": keyframe.get("easing", "linear")
                })
        
        return animations
    
    def _organize_subtitle_tracks(self, subtitle_data: List[Dict], title_data: List[Dict]) -> Dict[str, List[Dict]]:
        """ç»„ç»‡å­—å¹•è½¨é“"""
        return {
            "main_subtitles": [{
                "text": sub["text"],
                "start": sub["start"],
                "end": sub["end"],
                "style": {
                    "font_size": sub.get("font_size", 7),
                    "color": sub.get("color", "#FFFFFF"),
                    "border_color": sub.get("border_color", "#000000"),
                    "alignment": sub.get("alignment", "center"),
                    "position_y": sub.get("position_y", -810)
                }
            } for sub in subtitle_data],
            
            "title_overlay": [{
                "text": title["text"],
                "start": title["start"],
                "end": title["end"],
                "style": {
                    "font_size": title.get("font_size", 40),
                    "color": title.get("color", "#000000"),
                    "border_color": title.get("border_color", "#FFFFFF"),
                    "alignment": title.get("alignment", "center"),
                    "position_y": title.get("position_y", 0),
                    "letter_spacing": title.get("letter_spacing", 26),
                    "font_family": title.get("font_family", "ä¹¦å—ä½“"),
                    "animation": title.get("in_animation", "å¼¹å…¥")
                }
            } for title in title_data]
        }
    
    def _execute_composition(self, config: Dict) -> str:
        """æ‰§è¡Œè§†é¢‘åˆæˆ"""
        try:
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            output_filename = f"story_video_{int(torch.randint(0, 999999, (1,)).item())}.mp4"
            output_path = os.path.join(temp_dir, output_filename)
            
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„è§†é¢‘åˆæˆå¼•æ“
            # æ¯”å¦‚FFmpegã€MoviePyæˆ–ComfyUIçš„è§†é¢‘å¤„ç†èŠ‚ç‚¹
            
            # ä¸ºäº†æ¼”ç¤ºï¼Œåˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„åˆæˆè¿‡ç¨‹
            composition_script = self._generate_composition_script(config, output_path)
            
            print("Composition configuration:")
            print(f"  - Duration: {config['project_settings']['duration_microseconds']/1000000:.2f}s")
            print(f"  - Resolution: {config['project_settings']['width']}x{config['project_settings']['height']}")
            print(f"  - Audio tracks: {len(config['audio_tracks']['main_voice']) + len(config['audio_tracks']['background_music']) + len(config['audio_tracks']['sound_effects'])}")
            print(f"  - Video tracks: {len(config['video_tracks']['background_scenes']) + len(config['video_tracks']['character_overlay'])}")
            print(f"  - Subtitle segments: {len(config['subtitle_tracks']['main_subtitles'])}")
            print(f"  - Output: {output_path}")
            
            # æ¨¡æ‹Ÿåˆæˆè¿‡ç¨‹
            print("Executing video composition...")
            print("Audio mixing...")
            print("Video rendering with animations...")
            print("Subtitle overlay...")
            print("Final export...")
            
            # åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶ä½œä¸ºå ä½ç¬¦ï¼ˆå®é™…åº”ç”¨ä¸­è¿™é‡Œæ˜¯çœŸå®çš„è§†é¢‘æ–‡ä»¶ï¼‰
            with open(output_path, 'w') as f:
                f.write(f"# Story Video Composition Result\n")
                f.write(f"# Configuration: {len(json.dumps(config))} characters\n")
                f.write(f"# Generated at: {torch.randint(0, 999999, (1,)).item()}\n")
            
            print(f"Video composition completed: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"Composition execution error: {e}")
            return ""
    
    def _generate_composition_script(self, config: Dict, output_path: str) -> str:
        """ç”Ÿæˆåˆæˆè„šæœ¬ï¼ˆç”¨äºè°ƒè¯•å’Œæ—¥å¿—ï¼‰"""
        script_lines = [
            "# Story Video Composition Script",
            f"# Output: {output_path}",
            f"# Duration: {config['project_settings']['duration_microseconds']}Î¼s",
            "",
            "## Audio Tracks:"
        ]
        
        # éŸ³é¢‘è½¨é“ä¿¡æ¯
        for track_name, tracks in config["audio_tracks"].items():
            script_lines.append(f"### {track_name}: {len(tracks)} segments")
            for i, track in enumerate(tracks[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                script_lines.append(f"  - {i+1}: {track.get('start', 0)}-{track.get('end', 0)}Î¼s, vol={track.get('volume', 1.0)}")
        
        script_lines.extend([
            "",
            "## Video Tracks:"
        ])
        
        # è§†é¢‘è½¨é“ä¿¡æ¯
        for track_name, tracks in config["video_tracks"].items():
            script_lines.append(f"### {track_name}: {len(tracks)} segments")
            for i, track in enumerate(tracks[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                anim_count = len(track.get("animations", []))
                script_lines.append(f"  - {i+1}: {track.get('start', 0)}-{track.get('end', 0)}Î¼s, {anim_count} animations")
        
        return "\n".join(script_lines)


# ComfyUIèŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "StoryVideoComposer": StoryVideoComposer,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "StoryVideoComposer": "Story Video Composer",
}