"""
è§†é¢‘åˆæˆå™¨-åŸºäºå›¾ç‰‡
å°†é™æ€å›¾ç‰‡è½¬æ¢ä¸ºåŠ¨æ€è§†é¢‘ï¼Œæ”¯æŒå›¾åƒåŠ¨ç”»ã€éŸ³æ•ˆåº“ã€å­—ä½“æ ‡é¢˜ç­‰å…¨é¢åŠŸèƒ½
é€‚ç”¨äºä»å›¾ç‰‡ç”Ÿæˆè§†é¢‘çš„åœºæ™¯
"""

import os
import sys
import tempfile
import subprocess
import shutil
import torch
import torchaudio
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import folder_paths
from typing import List, Dict, Any, Tuple, Generator, Optional
import json
import math

# å¯¼å…¥éŸ³æ•ˆç®¡ç†å™¨ï¼ˆä»å½“å‰èŠ‚ç‚¹ç›®å½•ï¼‰
try:
    current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, current_dir)
    from audio_effects_manager import AudioEffectsManager
    AUDIO_EFFECTS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ éŸ³æ•ˆåº“ä¸å¯ç”¨: {e}")
    AUDIO_EFFECTS_AVAILABLE = False

class EnhancedVideoComposerV2:
    """
    å¢å¼ºç‰ˆè§†é¢‘åˆæˆå™¨V2 - æ”¯æŒéŸ³æ•ˆé€‰æ‹©çš„3è½¨éŸ³é¢‘ç³»ç»Ÿ

    æ–°å¢åŠŸèƒ½ï¼š
    1. éŸ³æ•ˆæ–‡ä»¶é€‰æ‹©
    2. éŸ³æ•ˆé£æ ¼/æ ‡ç­¾ç­›é€‰
    3. è‡ªå®šä¹‰éŸ³æ•ˆå¯¼å…¥
    """

    @classmethod
    def INPUT_TYPES(cls):
        # è·å–å¯ç”¨éŸ³æ•ˆé€‰é¡¹
        audio_effects_options = cls._get_audio_effects_options()

        return {
            "required": {
                "audio_list": ("*", {"tooltip": "éŸ³é¢‘åˆ—è¡¨ï¼Œæ¯ä¸ªéŸ³é¢‘å¯¹åº”ä¸€ä¸ªåœºæ™¯"}),
                "images": ("IMAGE", {"tooltip": "å›¾ç‰‡batchï¼Œæ¯å¼ å›¾ç‰‡å¯¹åº”ä¸€ä¸ªåœºæ™¯"}),
                "fps": ("INT", {
                    "default": 30,
                    "min": 15,
                    "max": 60,
                    "step": 1,
                    "tooltip": "è§†é¢‘å¸§ç‡"
                }),
                "width": ("INT", {
                    "default": 720,
                    "min": 480,
                    "max": 1920,
                    "step": 8,
                    "tooltip": "è§†é¢‘å®½åº¦"
                }),
                "height": ("INT", {
                    "default": 1280,
                    "min": 720,
                    "max": 2560,
                    "step": 8,
                    "tooltip": "è§†é¢‘é«˜åº¦"
                })
            },
            "optional": {
                "output_format": (["mp4", "avi", "mov"], {
                    "default": "mp4",
                    "tooltip": "è¾“å‡ºè§†é¢‘æ ¼å¼"
                }),
                "quality": (["high", "medium", "low"], {
                    "default": "medium",
                    "tooltip": "è§†é¢‘è´¨é‡"
                }),
                "animation_type": (["coze_zoom", "fade", "slide", "none"], {
                    "default": "coze_zoom",
                    "tooltip": "åŠ¨ç”»æ•ˆæœç±»å‹"
                }),
                "transition_duration": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "è½¬åœºæ—¶é•¿ï¼ˆç§’ï¼‰"
                }),

                # ğŸµ éŸ³æ•ˆé€‰æ‹©å‚æ•°
                "enable_audio_effects": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨éŸ³æ•ˆåº“ï¼ˆèƒŒæ™¯éŸ³ä¹+å¼€åœºéŸ³æ•ˆï¼‰"
                }),
                "opening_sound_choice": (audio_effects_options["opening"], {
                    "default": audio_effects_options["opening"][0] if audio_effects_options["opening"] else "æ— ",
                    "tooltip": "é€‰æ‹©å¼€åœºéŸ³æ•ˆ"
                }),
                "background_music_choice": (audio_effects_options["background"], {
                    "default": audio_effects_options["background"][0] if audio_effects_options["background"] else "æ— ",
                    "tooltip": "é€‰æ‹©èƒŒæ™¯éŸ³ä¹"
                }),
                "ambient_sound_choice": (audio_effects_options["ambient"], {
                    "default": audio_effects_options["ambient"][0] if audio_effects_options["ambient"] else "æ— ",
                    "tooltip": "é€‰æ‹©ç¯å¢ƒéŸ³æ•ˆ"
                }),

                # ğŸšï¸ éŸ³é‡æ§åˆ¶
                "background_music_volume": ("FLOAT", {
                    "default": 0.3,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "èƒŒæ™¯éŸ³ä¹éŸ³é‡ï¼ˆ0.3=30%ï¼‰"
                }),
                "opening_sound_volume": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "å¼€åœºéŸ³æ•ˆéŸ³é‡ï¼ˆ0.8=80%ï¼‰"
                }),
                "ambient_sound_volume": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "ç¯å¢ƒéŸ³æ•ˆéŸ³é‡ï¼ˆ0.5=50%ï¼‰"
                }),
                "voice_volume": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "ä¸»éŸ³è½¨ï¼ˆè¯­éŸ³ï¼‰éŸ³é‡"
                }),

                # ğŸ“‹ éŸ³æ•ˆé£æ ¼ç­›é€‰
                "audio_style_filter": (["å…¨éƒ¨", "å²è¯—", "å†å²", "åº„é‡", "å¤§æ°”", "è½»æ¾", "ç¥ç§˜", "åŠ¨æ„Ÿ"], {
                    "default": "å…¨éƒ¨",
                    "tooltip": "æŒ‰é£æ ¼ç­›é€‰éŸ³æ•ˆ"
                }),

                # ä¸»è§’å›¾ç›¸å…³å‚æ•°
                "character_image": ("IMAGE", {
                    "tooltip": "ä¸»è§’å›¾ç‰‡ï¼Œç”¨äºé¦–å¸§ç‰¹æ•ˆï¼ˆå¯é€‰ï¼‰"
                }),
                "enable_character_intro": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨ä¸»è§’å¼€åœºåŠ¨ç”»"
                }),
                "char_intro_scale_start": ("FLOAT", {
                    "default": 2.0,
                    "min": 0.5,
                    "max": 5.0,
                    "step": 0.1,
                    "tooltip": "ä¸»è§’å›¾å¼€å§‹ç¼©æ”¾æ¯”ä¾‹"
                }),
                "char_intro_scale_mid": ("FLOAT", {
                    "default": 1.2,
                    "min": 0.5,
                    "max": 3.0,
                    "step": 0.1,
                    "tooltip": "ä¸»è§’å›¾ä¸­é—´ç¼©æ”¾æ¯”ä¾‹"
                }),
                "char_intro_scale_end": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.5,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "ä¸»è§’å›¾ç»“æŸç¼©æ”¾æ¯”ä¾‹"
                }),
                "char_intro_mid_timing": ("FLOAT", {
                    "default": 0.533,
                    "min": 0.1,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "ä¸»è§’å›¾ä¸­é—´å…³é”®å¸§æ—¶é—´ç‚¹ï¼ˆç§’ï¼‰"
                }),
                # æ ‡é¢˜æ˜¾ç¤ºå‚æ•°
                "title_text": ("STRING", {
                    "default": "",
                    "tooltip": "è§†é¢‘æ ‡é¢˜æ–‡å­—ï¼ˆ2å­—ä¸»é¢˜ï¼‰"
                }),
                "enable_title": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "å¯ç”¨æ ‡é¢˜æ˜¾ç¤º"
                }),
                "title_duration": ("FLOAT", {
                    "default": 3.0,
                    "min": 1.0,
                    "max": 10.0,
                    "step": 0.5,
                    "tooltip": "æ ‡é¢˜æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰"
                }),
                "title_fontsize": ("INT", {
                    "default": 80,
                    "min": 30,
                    "max": 300,
                    "step": 5,
                    "tooltip": "æ ‡é¢˜å­—ä½“å¤§å°"
                }),
                "title_color": (["white", "black", "red", "gold", "blue"], {
                    "default": "white",
                    "tooltip": "æ ‡é¢˜é¢œè‰²"
                }),
                "title_font": (["è‡ªåŠ¨é€‰æ‹©", "Notoæ— è¡¬çº¿-å¸¸è§„", "Notoæ— è¡¬çº¿-ç²—ä½“", "Notoè¡¬çº¿ä½“", "æ–‡æ³‰é©¿æ­£é»‘", "Droidé»‘ä½“", "Arialé£æ ¼", "Helveticaé£æ ¼", "Timesé£æ ¼"], {
                    "default": "è‡ªåŠ¨é€‰æ‹©",
                    "tooltip": "æ ‡é¢˜å­—ä½“é€‰æ‹©ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰"
                })
            }
        }

    @classmethod
    def _get_audio_effects_options(cls):
        """è·å–å¯ç”¨éŸ³æ•ˆé€‰é¡¹"""
        options = {
            "opening": ["æ— ", "è‡ªåŠ¨é€‰æ‹©"],
            "background": ["æ— ", "è‡ªåŠ¨é€‰æ‹©"],
            "ambient": ["æ— ", "è‡ªåŠ¨é€‰æ‹©"]
        }

        if not AUDIO_EFFECTS_AVAILABLE:
            return options

        try:
            current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            sys.path.insert(0, current_dir)
            from audio_effects_manager import AudioEffectsManager

            manager = AudioEffectsManager()

            # è·å–å¼€åœºéŸ³æ•ˆåˆ—è¡¨
            opening_files = manager.list_files("opening")
            for file_info in opening_files:
                name = file_info.get("name", file_info.get("filename", "æœªçŸ¥"))
                options["opening"].append(name)

            # è·å–èƒŒæ™¯éŸ³ä¹åˆ—è¡¨
            bg_files = manager.list_files("background")
            for file_info in bg_files:
                name = file_info.get("name", file_info.get("filename", "æœªçŸ¥"))
                options["background"].append(name)

            # è·å–ç¯å¢ƒéŸ³æ•ˆåˆ—è¡¨
            ambient_files = manager.list_files("ambient")
            for file_info in ambient_files:
                name = file_info.get("name", file_info.get("filename", "æœªçŸ¥"))
                options["ambient"].append(name)

        except Exception as e:
            print(f"è·å–éŸ³æ•ˆé€‰é¡¹å¤±è´¥: {e}")

        return options

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("video_path", "info")
    FUNCTION = "compose_video_with_selectable_effects"
    CATEGORY = "ğŸ”¥ Shenglin/è§†é¢‘å¤„ç†"
    DESCRIPTION = "å¢å¼ºç‰ˆè§†é¢‘åˆæˆå™¨V2ï¼Œæ”¯æŒéŸ³æ•ˆé€‰æ‹©çš„3è½¨éŸ³é¢‘ç³»ç»Ÿ"

    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()

        # åˆå§‹åŒ–éŸ³æ•ˆç®¡ç†å™¨
        if AUDIO_EFFECTS_AVAILABLE:
            try:
                self.audio_effects_manager = AudioEffectsManager()
                print("âœ… éŸ³æ•ˆåº“V2åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ éŸ³æ•ˆåº“V2åˆå§‹åŒ–å¤±è´¥: {e}")
                self.audio_effects_manager = None
        else:
            self.audio_effects_manager = None

    def compose_video_with_selectable_effects(self, audio_list, images, fps=30, width=720, height=1280,
                                            output_format="mp4", quality="medium", animation_type="coze_zoom",
                                            transition_duration=0.5, enable_audio_effects=True,
                                            opening_sound_choice="è‡ªåŠ¨é€‰æ‹©", background_music_choice="è‡ªåŠ¨é€‰æ‹©",
                                            ambient_sound_choice="æ— ", background_music_volume=0.3,
                                            opening_sound_volume=0.8, ambient_sound_volume=0.5, voice_volume=1.0,
                                            audio_style_filter="å…¨éƒ¨", character_image=None, enable_character_intro=True,
                                            char_intro_scale_start=2.0, char_intro_scale_mid=1.2,
                                            char_intro_scale_end=1.0, char_intro_mid_timing=0.533,
                                            title_text="", enable_title=False, title_duration=3.0,
                                            title_fontsize=80, title_color="white", title_font="è‡ªåŠ¨é€‰æ‹©"):
        """
        å¢å¼ºç‰ˆè§†é¢‘åˆæˆV2 - æ”¯æŒéŸ³æ•ˆé€‰æ‹©
        """
        try:
            # åŸºç¡€æ£€æŸ¥
            if not isinstance(audio_list, list) or len(audio_list) == 0:
                raise ValueError("éŸ³é¢‘åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

            if images.shape[0] != len(audio_list):
                print(f"âš ï¸ è­¦å‘Šï¼šå›¾ç‰‡æ•°é‡({images.shape[0]}) ä¸éŸ³é¢‘æ•°é‡({len(audio_list)}) ä¸åŒ¹é…")
                min_count = min(images.shape[0], len(audio_list))
                images = images[:min_count]
                audio_list = audio_list[:min_count]

            print(f"ğŸ¬ å¼€å§‹å¢å¼ºç‰ˆè§†é¢‘åˆæˆV2ï¼š{len(audio_list)} ä¸ªåœºæ™¯")
            print(f"ğŸµ éŸ³æ•ˆé€‰æ‹©ï¼šå¼€åœº={opening_sound_choice}, èƒŒæ™¯={background_music_choice}, ç¯å¢ƒ={ambient_sound_choice}")

            # 1. åˆ†æéŸ³é¢‘æ—¶é•¿
            audio_durations = []
            total_duration = 0

            for i, audio_dict in enumerate(audio_list):
                if isinstance(audio_dict, dict) and "waveform" in audio_dict:
                    waveform = audio_dict["waveform"]
                    sample_rate = audio_dict["sample_rate"]

                    if len(waveform.shape) == 3:
                        waveform = waveform[0]

                    duration = waveform.shape[1] / sample_rate
                    audio_durations.append(duration)
                    total_duration += duration
                    print(f"ğŸµ åœºæ™¯ {i+1} éŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’")
                else:
                    raise ValueError(f"éŸ³é¢‘ {i} æ ¼å¼ä¸æ­£ç¡®")

            # 2. åˆæˆé€‰æ‹©æ€§éŸ³é¢‘ç³»ç»Ÿ
            print("ğŸ”Š å¼€å§‹é€‰æ‹©æ€§éŸ³é¢‘åˆæˆ...")
            if enable_audio_effects and self.audio_effects_manager:
                combined_audio_path = self._combine_audio_with_selectable_effects(
                    audio_list, total_duration,
                    opening_sound_choice, background_music_choice, ambient_sound_choice,
                    background_music_volume, opening_sound_volume, ambient_sound_volume, voice_volume,
                    audio_style_filter
                )
            else:
                print("ğŸ“¢ ä½¿ç”¨å•è½¨éŸ³é¢‘æ¨¡å¼")
                combined_audio_path = self._combine_audio_simple(audio_list, voice_volume)

            # 3. è§†é¢‘åˆæˆï¼ˆå¤ç”¨åŸæœ‰é€»è¾‘ï¼‰
            total_frames = sum(int(duration * fps) for duration in audio_durations)
            transition_frames_total = int(transition_duration * fps) * (len(images) - 1) if transition_duration > 0 else 0
            total_frames += transition_frames_total

            print("ğŸ¬ å¼€å§‹è§†é¢‘åˆæˆ...")
            output_filename = f"story_video_v2_{self._get_timestamp()}.{output_format}"
            video_path = os.path.join(self.output_dir, output_filename)

            # å¯¼å…¥åŸå§‹åˆæˆé€»è¾‘
            from .video_composer import VideoComposer
            original_composer = VideoComposer()

            frame_generator = original_composer._create_animated_frame_generator(
                images, audio_durations, fps, width, height,
                animation_type, transition_duration, character_image, enable_character_intro,
                char_intro_scale_start, char_intro_scale_mid, char_intro_scale_end, char_intro_mid_timing
            )

            # æ„å»ºæ ‡é¢˜é…ç½®
            title_config = {
                'enable_title': enable_title and title_text.strip(),
                'title_text': title_text.strip(),
                'fontsize': title_fontsize,
                'color': title_color,
                'duration': title_duration,
                'font': title_font
            } if enable_title and title_text.strip() else None

            original_composer._merge_video_audio_streaming(
                frame_generator, combined_audio_path, video_path, fps, quality, total_frames, title_config
            )

            # 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(combined_audio_path)
            except:
                pass

            # 5. ç”Ÿæˆè¯¦ç»†ä¿¡æ¯æŠ¥å‘Š
            effect_info = self._generate_effects_info(
                enable_audio_effects, opening_sound_choice, background_music_choice,
                ambient_sound_choice, audio_style_filter
            )

            title_info = f"'{title_text}' ({title_duration}s)" if enable_title and title_text.strip() else "æœªå¯ç”¨"

            info = f"""ğŸ¬ å¢å¼ºç‰ˆè§†é¢‘åˆæˆV2å®Œæˆ
ğŸ“ è¾“å‡ºè·¯å¾„: {video_path}
ğŸ“Š è§†é¢‘è§„æ ¼: {width}x{height}@{fps}fps
ğŸµ éŸ³æ•ˆé…ç½®: {effect_info}
ğŸ‘¤ ä¸»è§’åŠ¨ç”»: {'å·²å¯ç”¨' if enable_character_intro else 'æœªå¯ç”¨'}
ğŸ“ è§†é¢‘æ ‡é¢˜: {title_info}
ğŸ“ˆ æ€»æ—¶é•¿: {total_duration:.2f}ç§’
ğŸï¸ æ€»å¸§æ•°: {total_frames}"""

            print("âœ… å¢å¼ºç‰ˆè§†é¢‘åˆæˆV2å®Œæˆï¼")
            return (video_path, info)

        except Exception as e:
            error_msg = f"âŒ å¢å¼ºç‰ˆè§†é¢‘åˆæˆV2å¤±è´¥: {str(e)}"
            print(error_msg)
            return ("", error_msg)

    def _combine_audio_with_selectable_effects(self, audio_list, total_duration,
                                             opening_choice, background_choice, ambient_choice,
                                             bg_volume, opening_volume, ambient_volume, voice_volume,
                                             style_filter):
        """
        é€‰æ‹©æ€§éŸ³é¢‘åˆæˆï¼šæ ¹æ®ç”¨æˆ·é€‰æ‹©åˆæˆéŸ³è½¨
        """
        try:
            # 1. åˆæˆä¸»éŸ³è½¨ï¼ˆè¯­éŸ³ï¼‰
            voice_waveforms = []
            sample_rate = None

            for audio_dict in audio_list:
                waveform = audio_dict["waveform"]
                if len(waveform.shape) == 3:
                    waveform = waveform[0]
                voice_waveforms.append(waveform)
                sample_rate = audio_dict["sample_rate"]

            voice_combined = torch.cat(voice_waveforms, dim=1) * voice_volume
            print(f"ğŸ¤ ä¸»éŸ³è½¨ï¼š{voice_combined.shape[1]/sample_rate:.2f}ç§’ï¼ŒéŸ³é‡{voice_volume*100:.0f}%")

            # 2. å¤„ç†èƒŒæ™¯éŸ³ä¹
            bg_waveform = self._load_selected_audio("background", background_choice,
                                                  total_duration, sample_rate, bg_volume, style_filter)

            # 3. å¤„ç†å¼€åœºéŸ³æ•ˆ
            opening_track = self._load_selected_audio("opening", opening_choice,
                                                    voice_combined.shape[1]/sample_rate, sample_rate,
                                                    opening_volume, style_filter, is_opening=True)

            # 4. å¤„ç†ç¯å¢ƒéŸ³æ•ˆ
            ambient_track = self._load_selected_audio("ambient", ambient_choice,
                                                    total_duration, sample_rate, ambient_volume, style_filter)

            # 5. æ··åˆæ‰€æœ‰éŸ³è½¨
            min_length = min(voice_combined.shape[1], bg_waveform.shape[1],
                           opening_track.shape[1], ambient_track.shape[1])

            voice_combined = voice_combined[:, :min_length]
            bg_waveform = bg_waveform[:, :min_length]
            opening_track = opening_track[:, :min_length]
            ambient_track = ambient_track[:, :min_length]

            # æ··åˆéŸ³é¢‘
            final_audio = voice_combined + bg_waveform + opening_track + ambient_track

            # é˜²æ­¢éŸ³é¢‘å‰ªåˆ‡
            max_val = torch.max(torch.abs(final_audio))
            if max_val > 1.0:
                final_audio = final_audio / max_val * 0.95
                print(f"ğŸ”§ éŸ³é¢‘å‹ç¼©ï¼šå³°å€¼ä»{max_val:.2f}å‹ç¼©åˆ°0.95")

            # ä¿å­˜æ··åˆéŸ³é¢‘
            temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            torchaudio.save(temp_file.name, final_audio, sample_rate)
            temp_file.close()

            print(f"âœ… é€‰æ‹©æ€§éŸ³é¢‘åˆæˆå®Œæˆï¼š{final_audio.shape[1]/sample_rate:.2f}ç§’")
            return temp_file.name

        except Exception as e:
            print(f"âŒ é€‰æ‹©æ€§éŸ³é¢‘åˆæˆå¤±è´¥: {e}")
            return self._combine_audio_simple(audio_list, voice_volume)

    def _load_selected_audio(self, category, choice, duration_needed, sample_rate, volume, style_filter, is_opening=False):
        """åŠ è½½é€‰æ‹©çš„éŸ³æ•ˆ"""
        try:
            if choice == "æ— ":
                return torch.zeros(1, int(duration_needed * sample_rate))

            # è·å–éŸ³æ•ˆæ–‡ä»¶è·¯å¾„
            if choice == "è‡ªåŠ¨é€‰æ‹©":
                if style_filter != "å…¨éƒ¨":
                    # æŒ‰æ ‡ç­¾ç­›é€‰
                    audio_path = self.audio_effects_manager.get_ambient_sound([style_filter]) if category == "ambient" else self.audio_effects_manager.get_audio_file(category)
                else:
                    audio_path = self.audio_effects_manager.get_audio_file(category)
            else:
                # æŒ‰åç§°é€‰æ‹©ç‰¹å®šéŸ³æ•ˆ
                audio_path = self.audio_effects_manager.get_audio_file(category, choice)

            if not audio_path:
                print(f"ğŸ”‡ {category} - {choice}: æ— å¯ç”¨æ–‡ä»¶ï¼Œä½¿ç”¨é™éŸ³")
                return torch.zeros(1, int(duration_needed * sample_rate))

            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            waveform, file_sample_rate = torchaudio.load(audio_path)

            # é‡é‡‡æ ·
            if file_sample_rate != sample_rate:
                resampler = torchaudio.transforms.Resample(file_sample_rate, sample_rate)
                waveform = resampler(waveform)

            # è½¬æ¢ä¸ºå•å£°é“
            if waveform.shape[0] == 2:
                waveform = waveform.mean(dim=0, keepdim=True)

            # åº”ç”¨éŸ³é‡
            waveform = waveform * volume

            # å¤„ç†æ—¶é•¿
            if is_opening:
                # å¼€åœºéŸ³æ•ˆï¼šåªåœ¨å¼€å¤´æ’­æ”¾
                track = torch.zeros(1, int(duration_needed * sample_rate))
                opening_length = min(waveform.shape[1], track.shape[1])
                track[:, :opening_length] = waveform[:, :opening_length]
                duration_display = waveform.shape[1] / sample_rate
            else:
                # èƒŒæ™¯éŸ³ä¹/ç¯å¢ƒéŸ³æ•ˆï¼šå¾ªç¯æˆ–è£å‰ªåˆ°æŒ‡å®šé•¿åº¦
                length_needed = int(duration_needed * sample_rate)
                current_length = waveform.shape[1]

                if length_needed > current_length and category == "background":
                    # èƒŒæ™¯éŸ³ä¹éœ€è¦å¾ªç¯
                    repeats = (length_needed // current_length) + 1
                    waveform = waveform.repeat(1, repeats)

                track = waveform[:, :length_needed]
                duration_display = duration_needed

            print(f"ğŸµ {category} - {choice}: {duration_display:.2f}ç§’ï¼ŒéŸ³é‡{volume*100:.0f}%")
            return track

        except Exception as e:
            print(f"âŒ åŠ è½½éŸ³æ•ˆå¤±è´¥ ({category}-{choice}): {e}")
            return torch.zeros(1, int(duration_needed * sample_rate))

    def _combine_audio_simple(self, audio_list, voice_volume=1.0):
        """ç®€å•éŸ³é¢‘åˆæˆï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        waveforms = []
        sample_rate = None

        for audio_dict in audio_list:
            waveform = audio_dict["waveform"]
            if len(waveform.shape) == 3:
                waveform = waveform[0]
            waveforms.append(waveform * voice_volume)
            sample_rate = audio_dict["sample_rate"]

        combined_waveform = torch.cat(waveforms, dim=1)

        temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
        torchaudio.save(temp_file.name, combined_waveform, sample_rate)
        temp_file.close()

        return temp_file.name

    def _generate_effects_info(self, enabled, opening, background, ambient, style_filter):
        """ç”ŸæˆéŸ³æ•ˆé…ç½®ä¿¡æ¯"""
        if not enabled:
            return "å•è½¨éŸ³é¢‘"

        parts = []
        if opening != "æ— ":
            parts.append(f"å¼€åœº:{opening}")
        if background != "æ— ":
            parts.append(f"èƒŒæ™¯:{background}")
        if ambient != "æ— ":
            parts.append(f"ç¯å¢ƒ:{ambient}")

        effect_info = " | ".join(parts) if parts else "æ— éŸ³æ•ˆ"

        if style_filter != "å…¨éƒ¨":
            effect_info += f" (é£æ ¼:{style_filter})"

        return effect_info

    def _get_timestamp(self):
        """è·å–æ—¶é—´æˆ³"""
        import time
        return str(int(time.time()))

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "EnhancedVideoComposerV2": EnhancedVideoComposerV2
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "EnhancedVideoComposerV2": "ğŸ–¼ï¸ è§†é¢‘åˆæˆå™¨-åŸºäºå›¾ç‰‡"
}