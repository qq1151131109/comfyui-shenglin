"""
æ‰¹é‡RunningHubæ–‡ç”Ÿå›¾èŠ‚ç‚¹
åŸºäºRunningHub APIå’Œå·¥ä½œæµID 1958005140101935106
"""

import asyncio
import aiohttp
import json
import time
import os
import ssl
from typing import List, Dict, Any, Optional, Tuple
import torch
import numpy as np
from PIL import Image
import io
import base64
import hashlib

class RunningHubFluxTextToImage:
    """
    RunningHub Fluxæ–‡ç”Ÿå›¾èŠ‚ç‚¹

    æ”¯æŒåŒæ—¶ç”Ÿæˆå¤šå¼ å›¾ç‰‡ï¼ŒåŸºäºæŒ‡å®šçš„å·¥ä½œæµIDï¼Œä½¿ç”¨Fluxæ¨¡å‹
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompts": ("STRING", {
                    "multiline": True,
                    "default": "ä¸€ä¸ªç¾ä¸½çš„å¥³å­©\nä¸€åªå¯çˆ±çš„çŒ«å’ª\nå£®è§‚çš„å±±æ™¯",
                    "tooltip": "æ¯è¡Œä¸€ä¸ªæç¤ºè¯ï¼Œæ”¯æŒå¤šè¡Œè¾“å…¥"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "RunningHub APIå¯†é’¥"
                }),
                "workflow_id": ("STRING", {
                    "default": "1958005140101935106",
                    "tooltip": "RunningHubå·¥ä½œæµID"
                }),
                "prompt_node_id": ("STRING", {
                    "default": "39",
                    "tooltip": "æç¤ºè¯èŠ‚ç‚¹ID"
                }),
                "width": ("INT", {
                    "default": 1024,
                    "min": 256,
                    "max": 2048,
                    "step": 64,
                    "tooltip": "å›¾ç‰‡å®½åº¦"
                }),
                "height": ("INT", {
                    "default": 1024,
                    "min": 256,
                    "max": 2048,
                    "step": 64,
                    "tooltip": "å›¾ç‰‡é«˜åº¦"
                }),
                "resolution_node_id": ("STRING", {
                    "default": "5",
                    "tooltip": "åˆ†è¾¨ç‡æ§åˆ¶èŠ‚ç‚¹ID"
                }),
                "max_concurrent": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 3,
                    "step": 1,
                    "tooltip": "æœ€å¤§å¹¶å‘ç”Ÿæˆæ•°ï¼ˆå»ºè®®1-2ï¼Œé¿å…é˜Ÿåˆ—æ»¡ï¼‰"
                }),
                "retry_count": ("INT", {
                    "default": 2,
                    "min": 0,
                    "max": 5,
                    "step": 1,
                    "tooltip": "å¤±è´¥é‡è¯•æ¬¡æ•°"
                }),
                "retry_delay": ("INT", {
                    "default": 10,
                    "min": 5,
                    "max": 60,
                    "step": 5,
                    "tooltip": "é‡è¯•å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰"
                }),
                "timeout": ("INT", {
                    "default": 300,
                    "min": 60,
                    "max": 600,
                    "step": 10,
                    "tooltip": "å•ä¸ªä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
                })
            },
            "optional": {
                "supports_custom_resolution": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦æ”¯æŒè‡ªå®šä¹‰åˆ†è¾¨ç‡"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "info")
    FUNCTION = "generate_batch_images"
    CATEGORY = "ğŸ¨ RunningHub"
    DESCRIPTION = "ä½¿ç”¨RunningHub Fluxæ¨¡å‹æ‰¹é‡ç”Ÿæˆå›¾ç‰‡"

    def generate_batch_images(self, prompts: str, api_key: str, workflow_id: str,
                            prompt_node_id: str, width: int, height: int,
                            resolution_node_id: str, max_concurrent: int, retry_count: int,
                            retry_delay: int, timeout: int, supports_custom_resolution: bool = True):
        """
        æ‰¹é‡ç”Ÿæˆå›¾ç‰‡çš„ä¸»å‡½æ•°
        """
        if not api_key.strip():
            raise ValueError("APIå¯†é’¥ä¸èƒ½ä¸ºç©º")

        if not workflow_id.strip():
            raise ValueError("å·¥ä½œæµIDä¸èƒ½ä¸ºç©º")

        # è§£ææç¤ºè¯
        prompt_list = [p.strip() for p in prompts.strip().split('\n') if p.strip()]
        if not prompt_list:
            raise ValueError("è‡³å°‘éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„æç¤ºè¯")

        print(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(prompt_list)} å¼ å›¾ç‰‡...")

        # è¿è¡Œå¼‚æ­¥ç”Ÿæˆ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            results = loop.run_until_complete(
                self._batch_generate_async(
                    prompt_list, api_key, workflow_id, prompt_node_id,
                    width, height, resolution_node_id, max_concurrent,
                    retry_count, retry_delay, timeout, supports_custom_resolution
                )
            )
        finally:
            loop.close()

        # å¤„ç†ç»“æœ
        images = []
        info_lines = []

        for i, result in enumerate(results):
            if result is not None:
                images.append(result['image'])
                info_lines.append(f"å›¾ç‰‡ {i+1}: æˆåŠŸç”Ÿæˆ ({result['file_size']} bytes)")
            else:
                # å¤±è´¥çš„ä»»åŠ¡ç”¨é»‘è‰²å›¾ç‰‡å ä½
                placeholder = torch.zeros((height, width, 3), dtype=torch.float32)
                images.append(placeholder)
                info_lines.append(f"å›¾ç‰‡ {i+1}: ç”Ÿæˆå¤±è´¥")

        # åˆå¹¶å›¾ç‰‡å¼ é‡
        if images:
            image_batch = torch.stack(images, dim=0)
        else:
            image_batch = torch.zeros((1, height, width, 3), dtype=torch.float32)

        info_text = "\n".join(info_lines)

        return (image_batch, info_text)

    async def _batch_generate_async(self, prompt_list: List[str], api_key: str,
                                  workflow_id: str, prompt_node_id: str,
                                  width: int, height: int, resolution_node_id: str,
                                  max_concurrent: int, retry_count: int, retry_delay: int,
                                  timeout: int, supports_custom_resolution: bool) -> List[Optional[Dict]]:
        """
        å¼‚æ­¥æ‰¹é‡ç”Ÿæˆå›¾ç‰‡
        """
        semaphore = asyncio.Semaphore(max_concurrent)

        async def generate_single(prompt: str, index: int) -> Optional[Dict]:
            async with semaphore:
                for attempt in range(retry_count + 1):
                    try:
                        if attempt == 0:
                            print(f"å¼€å§‹ç”Ÿæˆå›¾ç‰‡ {index+1}: {prompt[:50]}...")
                        else:
                            print(f"å›¾ç‰‡ {index+1} é‡è¯• {attempt}/{retry_count}: {prompt[:50]}...")

                        result = await self._generate_single_image(
                            prompt, api_key, workflow_id, prompt_node_id,
                            width, height, resolution_node_id, timeout,
                            supports_custom_resolution
                        )
                        print(f"å›¾ç‰‡ {index+1} ç”ŸæˆæˆåŠŸ")
                        return result
                    except Exception as e:
                        error_msg = str(e)
                        print(f"å›¾ç‰‡ {index+1} ç¬¬ {attempt+1} æ¬¡å°è¯•å¤±è´¥: {error_msg}")

                        # å¦‚æœæ˜¯é˜Ÿåˆ—æ»¡æˆ–å¸¸è§é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
                        if attempt < retry_count and ("timeout" in error_msg.lower() or "failed" in error_msg.lower()):
                            print(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                            await asyncio.sleep(retry_delay)
                        elif attempt < retry_count:
                            # å…¶ä»–é”™è¯¯ä¹Ÿç­‰å¾…ä¸€ä¸‹å†é‡è¯•
                            await asyncio.sleep(retry_delay // 2)
                        else:
                            print(f"å›¾ç‰‡ {index+1} æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")

                return None

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        tasks = [generate_single(prompt, i) for i, prompt in enumerate(prompt_list)]
        results = await asyncio.gather(*tasks, return_exceptions=False)

        return results

    async def _generate_single_image(self, prompt: str, api_key: str, workflow_id: str,
                                   prompt_node_id: str, width: int, height: int,
                                   resolution_node_id: str, timeout: int,
                                   supports_custom_resolution: bool) -> Dict:
        """
        ç”Ÿæˆå•å¼ å›¾ç‰‡
        """
        # æ„å»ºèŠ‚ç‚¹å‚æ•°åˆ—è¡¨
        node_list = [
            {
                "nodeId": prompt_node_id,
                "fieldName": "text",
                "fieldValue": prompt
            }
        ]

        # å¦‚æœæ”¯æŒè‡ªå®šä¹‰åˆ†è¾¨ç‡ï¼Œæ·»åŠ åˆ†è¾¨ç‡æ§åˆ¶
        if supports_custom_resolution and resolution_node_id:
            node_list.extend([
                {
                    "nodeId": resolution_node_id,
                    "fieldName": "width",
                    "fieldValue": width
                },
                {
                    "nodeId": resolution_node_id,
                    "fieldName": "height",
                    "fieldValue": height
                }
            ])

        payload = {
            "apiKey": api_key,
            "workflowId": workflow_id,
            "nodeInfoList": node_list
        }

        headers = {
            "Host": "www.runninghub.cn",
            "Content-Type": "application/json"
        }

        # åˆ›å»ºSSLä¸Šä¸‹æ–‡
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE

        # åˆ›å»ºè¿æ¥å™¨
        connector = aiohttp.TCPConnector(ssl=ssl_context)

        async with aiohttp.ClientSession(connector=connector) as session:
            # åˆ›å»ºä»»åŠ¡
            create_url = "https://www.runninghub.cn/task/openapi/create"
            async with session.post(create_url, json=payload, headers=headers) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"åˆ›å»ºä»»åŠ¡å¤±è´¥ {response.status}: {error_text}")

                result = await response.json()
                if result.get('code') != 0:
                    error_msg = result.get('msg', 'ä»»åŠ¡åˆ›å»ºå¤±è´¥')
                    raise Exception(f"RunningHub APIé”™è¯¯: {error_msg}")

                task_id = result.get('data', {}).get('taskId')
                if not task_id:
                    raise Exception("æœªè¿”å›ä»»åŠ¡ID")

            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            status_url = "https://www.runninghub.cn/task/openapi/status"
            outputs_url = "https://www.runninghub.cn/task/openapi/outputs"

            status_payload = {"taskId": task_id, "apiKey": api_key}

            start_time = time.time()
            while time.time() - start_time < timeout:
                await asyncio.sleep(2)

                try:
                    # æ£€æŸ¥çŠ¶æ€
                    async with session.post(status_url, json=status_payload, headers=headers) as status_response:
                        if status_response.status == 200:
                            status_result = await status_response.json()
                            if status_result.get('code') == 0:
                                task_status = status_result.get('data')

                                if task_status == 'SUCCESS':
                                    # è·å–ç»“æœ
                                    outputs_payload = {"taskId": task_id, "apiKey": api_key}
                                    async with session.post(outputs_url, json=outputs_payload, headers=headers) as outputs_response:
                                        if outputs_response.status == 200:
                                            outputs_result = await outputs_response.json()
                                            if outputs_result.get('code') == 0:
                                                outputs = outputs_result.get('data', [])

                                                # æŸ¥æ‰¾å›¾åƒURL
                                                for item in outputs:
                                                    image_url = None
                                                    if isinstance(item, dict) and 'fileUrl' in item:
                                                        image_url = item['fileUrl']
                                                    elif isinstance(item, str) and item.startswith('http'):
                                                        image_url = item

                                                    if image_url:
                                                        # ä¸‹è½½å›¾åƒ
                                                        async with session.get(image_url) as img_response:
                                                            if img_response.status == 200:
                                                                image_data = await img_response.read()

                                                                # è½¬æ¢ä¸ºtensor
                                                                pil_image = Image.open(io.BytesIO(image_data))
                                                                if pil_image.mode != 'RGB':
                                                                    pil_image = pil_image.convert('RGB')

                                                                # è½¬æ¢ä¸ºComfyUIæ ¼å¼çš„tensor
                                                                image_np = np.array(pil_image).astype(np.float32) / 255.0
                                                                image_tensor = torch.from_numpy(image_np)

                                                                return {
                                                                    'image': image_tensor,
                                                                    'file_size': len(image_data),
                                                                    'task_id': task_id,
                                                                    'url': image_url
                                                                }

                                                raise Exception(f"è¾“å‡ºä¸­æœªæ‰¾åˆ°å›¾åƒURL: {outputs}")

                                elif task_status == 'FAILED':
                                    raise Exception(f"ä»»åŠ¡å¤±è´¥: {task_id}")

                except Exception as e:
                    # å¦‚æœæ˜¯æœ€ç»ˆé”™è¯¯ï¼ŒæŠ›å‡ºï¼›å¦åˆ™ç»§ç»­è½®è¯¢
                    if "ä»»åŠ¡å¤±è´¥" in str(e) or "è¾“å‡ºä¸­æœªæ‰¾åˆ°" in str(e):
                        raise
                    continue

            raise Exception(f"ä»»åŠ¡è¶…æ—¶: {task_id} ({timeout}ç§’)")

# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "RunningHubFluxTextToImage": RunningHubFluxTextToImage
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "RunningHubFluxTextToImage": "RunningHub Fluxæ–‡ç”Ÿå›¾"
}